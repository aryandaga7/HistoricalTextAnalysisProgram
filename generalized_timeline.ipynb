{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Timeline Program\n",
    "## Goal:\n",
    "#### This program would generate timelines of word frequencies, using given words. \n",
    "\n",
    "## Input:\n",
    "#### This program requires the number of words we want, and the regex of those words as inputs. \n",
    "\n",
    "## Result:\n",
    "#### This program will generate 2 timelines. The first one will show each word's frequency with respect of time, and the second timeline will show the combined word frequency of all words with repect of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Enter the words we want into words_arr. For example, if we want to see words 'apple' 'bee' 'car', we would do \n",
    "words_arr = [\"apple\",\"bee\",\"car\"]\n",
    "\n",
    "then, enter the corresponding regular expressions into the regex_arr. Following the previouse example, the regex_arr would be\n",
    "regex_arr = [\"\\bapple\\b\",\"\\bbee\\b\",\"\\bcar\\b\"]\n",
    "\n",
    "\"\"\"\n",
    "#words_arr = [\"king\", \"queen\", \"majesty\"]\n",
    "words_arr = [\"male\", \"female\"]\n",
    "#regex_arr = [r\"\\bking(s|and)?\\b\", r\"\\b(and)?queen(s|and)?\\b\", r\"\\bmajest(y|e){1}\\b\"]\n",
    "# regex_arr for male and female have bee listed below\n",
    "regex_arr_male = [r\"\\bmen\\b\", r\"\\bman\\b\", r\"father.?\\b\", r\"\\bson.?\\b\", r\"lord.?\\b\", r\"\\bhim\\b\", r\"\\bhe\\b\", r\"\\bmale.?\\b\"]\n",
    "regex_arr_female = [r\"\\bwomen\\b\", r\"\\bwoman\\b\", r\"mother.?\\b\", r\"\\bdaughter.?\\b\", r\"lady.?\\b\", r\"\\bher\\b\", r\"\\bshe\\b\", r\"\\bfemale.?\\b\"]\n",
    "\"\"\"\n",
    "save_file determines if you want to save the metadata (word frequencies and ratios)\n",
    "\n",
    "True will save the file if not exist, update if exist (by deleting and saving again)\n",
    "False will not save the file\n",
    "\"\"\"\n",
    "save_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nprogram_files_path = \"D:/corping2022/dataad/outputFiles\"\\nmetadata_file_path = \"D:/corping2022/dataad/inputFiles/metadataERallFiles.csv\"\\nall_tokenized_files_path = \"D:/corping2022/dataad/inputFiles/englishReportsProcessedAllFiles\"\\nplots_saving_path = \"D:/corping2022/dataad/outputFiles\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Paths ##\n",
    "\n",
    "\n",
    "program_files_path = \"/Users/aryandaga/Desktop/Research Project Files\"\n",
    "metadata_file_path = \"/Users/aryandaga/Desktop/metadataERallFiles.csv\"\n",
    "all_tokenized_files_path = \"/Users/aryandaga/Desktop/englishReportsProcessedEarlyAllFiles2\"\n",
    "plots_saving_path = \"/Users/aryandaga/Desktop/Research Project Files\"\n",
    "\"\"\"\n",
    "\n",
    "program_files_path = \"D:/corping2022/dataad/outputFiles\"\n",
    "metadata_file_path = \"D:/corping2022/dataad/inputFiles/metadataERallFiles.csv\"\n",
    "all_tokenized_files_path = \"D:/corping2022/dataad/inputFiles/englishReportsProcessedAllFiles\"\n",
    "plots_saving_path = \"D:/corping2022/dataad/outputFiles\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries ##\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_param is the number of files that will be run\n",
    "\n",
    "index_param = 10\n",
    "\n",
    "# Parameters for the graph\n",
    "params = {\n",
    "    \"axes.labelsize\": 200,\n",
    "    \"axes.titlesize\": 200,\n",
    "    \"xtick.labelsize\": 150,\n",
    "    \"ytick.labelsize\": 150\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing the dataframe for our timeline...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/aryandaga/Desktop/metadataERallFiles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The code above is for the previous regex_arr\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Printing extra coloumns for male and female\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitializing the dataframe for our timeline...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m timeline_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(timeline_df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/aryandaga/Desktop/metadataERallFiles.csv'"
     ]
    }
   ],
   "source": [
    "word_count = len(words_arr)\n",
    "\n",
    "# Checking if the number of regex matches the number of words\n",
    "\"\"\"\n",
    "if len(regex_arr) != word_count:\n",
    "    raise Exception(\"number of words doesn't match number of regex!\")\n",
    "else:\n",
    "    print(\"initializing the dataframe for our timeline...\")\n",
    "    timeline_df = pd.read_csv(metadata_file_path)\n",
    "    print(timeline_df.columns)\n",
    "\"\"\"\n",
    "# The code above is for the previous regex_arr\n",
    "\n",
    "# Printing extra coloumns for male and female\n",
    "print(\"initializing the dataframe for our timeline...\")\n",
    "timeline_df = pd.read_csv(metadata_file_path)\n",
    "print(timeline_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping the metadata we need\n",
    "columns_to_keep = [\"file_name\", \"year\", \"total_word_count\"]\n",
    "timeline_df = timeline_df[columns_to_keep]\n",
    "\n",
    "timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns we need, each word need a frequency and a ratio column. In total we need 2 * len(words_arr) number of \n",
    "# new columns\n",
    "\n",
    "for i in range(word_count):\n",
    "    col_name = words_arr[i]\n",
    "    word_freq = col_name + \"_freq\"\n",
    "    word_ratio = col_name + \"_ratio\"\n",
    "    land_freq = col_name + \"_land_freq\"\n",
    "    land_ratio = col_name + \"_land_ratio\"\n",
    "    timeline_df[word_freq] = 0\n",
    "    timeline_df[word_ratio] = 0\n",
    "    timeline_df[land_freq] = 0\n",
    "    timeline_df[land_ratio] = 0\n",
    "    \n",
    "\n",
    "timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#    opening every file, reading line by line, searching for each regex pattern,            #\n",
    "#      and updating the new values within the dataframe                                     #\n",
    "#############################################################################################\n",
    "\"\"\"\n",
    "### TEST\n",
    "test = 0\n",
    "### END\n",
    "\"\"\"\n",
    "\n",
    "updated_freq_arr = [] # This would store the updated value for every word's frequency\n",
    "\n",
    "# Getting column names from timeline_df\n",
    "columns = [\"filename\",\"year\",\"wordcount\"]\n",
    "for i in range(word_count):\n",
    "    columns.append(words_arr[i] + \"_freq\")\n",
    "    columns.append(words_arr[i] + \"_ratio\")\n",
    "\n",
    "updated_timeline_df = pd.DataFrame(columns=columns) # We will store the updated timeline_df into a new dataframe\n",
    "\n",
    "#df1 = pd.DataFrame([]) # Dataframe that collects 10 words before a she/he\n",
    "#Enter word and word_limit words before it will be printed below\n",
    "word_to_find = 'she'\n",
    "word_limit = 10\n",
    "\n",
    "\n",
    "#print(columns) \n",
    "\n",
    "# Initializing all word frequency to 0 first\n",
    "for i in range(word_count):\n",
    "    updated_freq_arr.append(0)\n",
    "\n",
    "# Iterating every row of the dataframe\n",
    "for index, row in timeline_df.iterrows():\n",
    "    # if statement which breaks the loop after iterating through 100 files\n",
    "    if index == index_param:\n",
    "        break\n",
    "    # getting filename\n",
    "    filename = row[\"file_name\"] # \"tokenized_%s\" % row[\"file_name\"]\n",
    "    # getting file path\n",
    "    filepath = os.path.join(all_tokenized_files_path, filename)\n",
    "    \n",
    "    # opening the tokenized file\n",
    "    with open(filepath) as file:\n",
    "        # reading line by line\n",
    "        for line in file:\n",
    "            # matching every regexs in regex arr\n",
    "            for i in range(len(regex_arr_male)): \n",
    "                # updating value into temp arr\n",
    "                #updated_freq_arr[i] += len(re.findall(regex_arr[i], line))\n",
    "                # updating values for male and female individually\n",
    "                updated_freq_arr[0] += len(re.findall(regex_arr_male[i], line))\n",
    "                updated_freq_arr[1] += len(re.findall(regex_arr_female[i], line))\n",
    "    file.close()\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------#\n",
    "    # program for getting 10 word before he/she\n",
    "    \n",
    "    \"\"\"\n",
    "    word_to_find = 'she'\n",
    "    \n",
    "    # opening the tokenized file\n",
    "    with open(filepath) as file:\n",
    "        file_10_words_list = []\n",
    "        cont = 0\n",
    "        for line in file:\n",
    "            new_line = line.split(' ')\n",
    "            for c in range(10):\n",
    "                new_line.insert(0, '')\n",
    "            try:\n",
    "                word_index = new_line.index(word_to_find.lower())\n",
    "            except ValueError:\n",
    "                print(f\"Line {cont + 1} hasn't got {word_to_find.title()}\")\n",
    "            else:\n",
    "                words_before_list = [new_line[element + word_index] for element in range(-10, 0)]\n",
    "                words_before_list = [element for element in words_before_list if element != '']\n",
    "                file_10_words_list.append(words_before_list)\n",
    "            cont += 1\n",
    "        #values = ''.join(str(v) for v in file_10_words_list)\n",
    "        #print(file_10_words_list)\n",
    "        df1 = df1.append(file_10_words_list)\n",
    "                      \n",
    "    file.close()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filepath) as file:\n",
    "        word_list = file.read().split()\n",
    "        #print(word_list)\n",
    "        for index, words in enumerate(word_list):\n",
    "            if(words.lower() == word_to_find):\n",
    "                #print(words, index)\n",
    "                if(index < word_limit):\n",
    "                    start_index = 0\n",
    "                else:\n",
    "                    start_index = index - word_limit\n",
    "                \n",
    "                #sentence = ' '.join(words_list[start_index : index])\n",
    "                print(word_list[start_index:index+1])            \n",
    "            \n",
    "    file.close()\n",
    "\n",
    "    #-----------------------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    # new_row_value would be the new value we update our row to\n",
    "    new_row_value = [row[\"file_name\"], row[\"year\"], row[\"total_word_count\"]]\n",
    "    \n",
    "    CONSTANT = 10000\n",
    "\n",
    "    # adding freq and ratio values\n",
    "    for i in range(word_count):\n",
    "        # adding freq\n",
    "        new_row_value.append(updated_freq_arr[i])\n",
    "        # adding ratio\n",
    "        if row[\"total_word_count\"] == 0:\n",
    "            new_row_value.append(0)\n",
    "        else:\n",
    "            new_row_value.append(updated_freq_arr[i] / row[\"total_word_count\"] * CONSTANT)\n",
    "\n",
    "    # Adding the new_row_value to updated_timeline_df\n",
    "    updated_timeline_df.loc[updated_timeline_df.shape[0]] = new_row_value\n",
    "    \n",
    "    # Resetting word freq arry to 0\n",
    "    updated_freq_arr = []\n",
    "    for i in range(word_count):\n",
    "        updated_freq_arr.append(0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_arr = [\"male\", \"female\"]\n",
    "regex_arr_male = [r\"\\bmen\\b\", r\"\\bman\\b\", r\"father.?\\b\", r\"\\bson.?\\b\", r\"lord.?\\b\", r\"\\bhim\\b\", r\"\\bhe\\b\", r\"\\bmale.?\\b\", r\"\\bbachelor\\b\", r\"\\bwidower\\b\", r\"\\bmonsieur\\b\", r\"\\blad\\b\", r\"\\bchap\\b\", r\"\\bdude\\b\", r\"\\bgentleman\\b\", r\"\\bguy\\b\", r\"\\bmate\\b\"]\n",
    "regex_arr_female = [r\"\\bwomen\\b\", r\"\\bwoman\\b\", r\"mother.?\\b\", r\"\\bdaughter.?\\b\", r\"lady.?\\b\", r\"\\bher\\b\", r\"\\bshe\\b\", r\"\\bfemale.?\\b\", r\"\\bmaiden\\b\", r\"\\bwidow\\b\", r\"\\bmadame\\b\", r\"\\blass\\b\", r\"\\bchapess\\b\", r\"\\bdamsel\\b\", r\"\\bgentlewoman\\b\", r\"\\bgal\\b\", r\"\\bsheila\\b\"]\n",
    "land_keywords = [r\"\\bland\\b\", r\"\\bpropert.+\\b\"]\n",
    "#Program that goes through the files and creates ratios for male/female words that occur with land and property words\n",
    "\n",
    "# Create empty lists to store the ratios\n",
    "male_land_list = []\n",
    "female_land_list = []\n",
    "male_land_ratio = []\n",
    "female_land_ratio = []\n",
    "\n",
    "for index, row in timeline_df.iterrows():\n",
    "    # if statement which breaks the loop after iterating through 100 files\n",
    "    if index == index_param:\n",
    "        break\n",
    "    # getting filename\n",
    "    filename = row[\"file_name\"] # \"tokenized_%s\" % row[\"file_name\"]\n",
    "    # getting file path\n",
    "    filepath = os.path.join(all_tokenized_files_path, filename)\n",
    "    \n",
    "    # opening the tokenized file\n",
    "    with open(filepath) as file:\n",
    "        \n",
    "        words = file.read().split()\n",
    "        word_indices = {word: [i for i, w in enumerate(words) if w == word] for word in words_arr}\n",
    "\n",
    "        # Initialize variables to store the counts of male, female, and land keyword occurrences\n",
    "        male_count = 0\n",
    "        female_count = 0\n",
    "        male_land_count = 0\n",
    "        female_land_count = 0\n",
    "\n",
    "        # Iterate over the word indices\n",
    "        for i in range(len(words)):\n",
    "            for regex in regex_arr_male:\n",
    "                if re.match(regex, words[i]):\n",
    "                    male_count += 1\n",
    "                    # Check for land keyword occurrences 5 words before and after the male word\n",
    "                    for j in range(-5, 6):\n",
    "                        if j == 0:\n",
    "                            continue\n",
    "                        if i + j >= 0 and i + j < len(words):\n",
    "                            for land_regex in land_keywords:\n",
    "                                if re.match(land_regex, words[i + j]):\n",
    "                                    male_land_count += 1\n",
    "                                    break\n",
    "\n",
    "            for regex in regex_arr_female:\n",
    "                if re.match(regex, words[i]):\n",
    "                    female_count += 1\n",
    "                    # Check for land keyword occurrences 5 words before and after the female word\n",
    "                    for j in range(-5, 6):\n",
    "                        if j == 0:\n",
    "                            continue\n",
    "                        if i + j >= 0 and i + j < len(words):\n",
    "                            for land_regex in land_keywords:\n",
    "                                if re.match(land_regex, words[i + j]):\n",
    "                                    female_land_count += 1\n",
    "                                    break\n",
    "\n",
    "        # Calculate the ratios and append them to the respective lists\n",
    "        if male_count > 0:\n",
    "            male_land_ratio.append(male_land_count / male_count)\n",
    "            male_land_list.append(male_land_count)\n",
    "        else:\n",
    "            male_land_ratio.append(0)\n",
    "            male_land_list.append(0)\n",
    "            \n",
    "        if female_count > 0:\n",
    "            female_land_ratio.append(female_land_count / female_count)\n",
    "            female_land_list.append(female_land_count)\n",
    "        else:\n",
    "            female_land_ratio.append(0)\n",
    "            female_land_list.append(0)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "# Add the new columns to the updated_timeline_df\n",
    "updated_timeline_df[\"male_land_count\"] = male_land_list\n",
    "updated_timeline_df[\"female_land_count\"] = female_land_list\n",
    "updated_timeline_df[\"male_land_ratio\"] = male_land_ratio\n",
    "updated_timeline_df[\"female_land_ratio\"] = female_land_ratio\n",
    "\n",
    "updated_timeline_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Saving the file\n",
    "\n",
    "if save_file:\n",
    "    filename = \"\"\n",
    "    for word in words_arr:\n",
    "        filename += (word + '_')\n",
    "    filename += \"metadata.csv\"\n",
    "    \n",
    "    ### Printing filename\n",
    "    print(filename)\n",
    "\n",
    "    path = os.path.join(program_files_path, filename)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    \n",
    "    print(f\"saving the metadata file under path: {path}\")\n",
    "    updated_timeline_df.to_csv(path)\n",
    "else:\n",
    "    print(\"we are not saving any files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_timeline_df.set_index([\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouping the data by year\n",
    "grouped = updated_timeline_df.groupby([\"year\"]).sum()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting columns we need\n",
    "columns_needed = []\n",
    "for word in words_arr:\n",
    "    columns_needed.append(word+\"_freq\")\n",
    "    columns_needed.append(word+\"_ratio\")\n",
    "columns_needed += [\"wordcount\",\"male_land_count\", \"female_land_count\", \"male_land_ratio\", \"female_land_ratio\"]\n",
    "\n",
    "\n",
    "print(columns_needed)\n",
    "grouped = grouped[columns_needed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only keeping data from year 1558 and later\n",
    "grouped = grouped.loc[\"1558\":]\n",
    "\n",
    "year_arr = grouped.index.values.tolist()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the individual plot\n",
    "ratio_columns = [word + \"_ratio\" for word in words_arr]\n",
    "ratio_data = grouped[ratio_columns]\n",
    "\n",
    "# Setting xticks\n",
    "ax.set_xticks(np.arange(1558, 1875, step=30))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(200,50))\n",
    "\n",
    "for ratio in ratio_columns:\n",
    "    ax.plot(year_arr, ratio_data[ratio].tolist(), marker='o', markersize=8, label=ratio, linewidth=6)    \n",
    "\n",
    "# Setting graph properties\n",
    "plt.rcParams.update(params)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Individual Plot\")\n",
    "ax.legend(prop={\"size\": 90})\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVING the plot\n",
    "folder_name = \"\"\n",
    "for word in words_arr:\n",
    "    folder_name += word + '_'\n",
    "folder_name += \"plots\"\n",
    "\n",
    "the_path = os.path.join(plots_saving_path, folder_name)\n",
    "\n",
    "if os.path.exists(the_path):\n",
    "    print(f\"path: {the_path} exists, updating by deleting and re-saving.\")\n",
    "    shutil.rmtree(the_path)\n",
    "    os.mkdir(the_path)\n",
    "    fig.savefig(os.path.join(the_path, \"individual.png\"))\n",
    "    \n",
    "else:\n",
    "    print(f\"creating path: {the_path}\")\n",
    "    os.mkdir(the_path)\n",
    "    fig.savefig(os.path.join(the_path, \"individual.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the combined plot\n",
    "combined_ratio = []\n",
    "for idx, col in grouped.iterrows():\n",
    "    total_freq = 0\n",
    "    wordcount = col[\"wordcount\"]\n",
    "    for word in words_arr:\n",
    "        total_freq += col[word+\"_freq\"]\n",
    "    combined = total_freq / wordcount * CONSTANT\n",
    "    combined_ratio.append(combined)\n",
    "\n",
    "grouped[\"combined_ratio\"] = combined_ratio\n",
    "combined_ratio_df = grouped[[\"combined_ratio\"]]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(200,50))\n",
    "\n",
    "ax.plot(year_arr, combined_ratio_df[\"combined_ratio\"].tolist(), marker='o', markersize=8, label=\"combined_ratio\", linewidth=6)    \n",
    "\n",
    "\"\"\"\n",
    "# Parameters for the graph\n",
    "params = {\n",
    "    \"axes.labelsize\": 200,\n",
    "    \"axes.titlesize\": 200,\n",
    "    \"xtick.labelsize\": 150,\n",
    "    \"ytick.labelsize\": 150\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Setting graph properties\n",
    "plt.rcParams.update(params)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_xticks(np.arange(1558, 1875, step=30))\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Combined Plot\")\n",
    "ax.legend(prop={\"size\": 180})\n",
    "ax.grid()\n",
    "\n",
    "### Saving the plot\n",
    "fig.savefig(os.path.join(the_path, \"combined.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the individual plot for male and female land ratios\n",
    "land_ratio_columns = [word + \"_ratio\" for word in [\"male_land\", \"female_land\"]]\n",
    "\n",
    "fig, axs = plt.subplots(len(land_ratio_columns), 1, figsize=(200, 50*len(land_ratio_columns)))\n",
    "\n",
    "for i, col in enumerate(land_ratio_columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(year_arr, grouped[col].tolist(), marker='o', markersize=8, label=col, linewidth=6)    \n",
    "    ax.set_xticks(np.arange(1558, 1875, step=30))\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Ratio\")\n",
    "    ax.set_title(col.capitalize().replace(\"_\", \" \") + \" ratio\")\n",
    "    ax.legend(prop={\"size\": 90})\n",
    "    ax.grid()\n",
    "\n",
    "### SAVING the plot\n",
    "folder_name = \"\"\n",
    "for word in words_arr:\n",
    "    folder_name += word + '_'\n",
    "folder_name += \"land_ratio_plots\"\n",
    "\n",
    "the_path = os.path.join(plots_saving_path, folder_name)\n",
    "\n",
    "if os.path.exists(the_path):\n",
    "    print(f\"path: {the_path} exists, updating by deleting and re-saving.\")\n",
    "    shutil.rmtree(the_path)\n",
    "    os.mkdir(the_path)\n",
    "    \n",
    "else:\n",
    "    print(f\"creating path: {the_path}\")\n",
    "    os.mkdir(the_path)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(os.path.join(the_path, land_ratio_columns[i]+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the combined plot\n",
    "combined_ratio = []\n",
    "for idx, col in grouped.iterrows():\n",
    "    total_freq = 0\n",
    "    wordcount = col[\"wordcount\"]\n",
    "    for word in words_arr:\n",
    "        total_freq += col[word+\"_land_count\"]\n",
    "    combined = total_freq / wordcount * CONSTANT\n",
    "    combined_ratio.append(combined)\n",
    "\n",
    "grouped[\"combined_ratio\"] = combined_ratio\n",
    "combined_ratio_df = grouped[[\"combined_ratio\"]]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(200,50))\n",
    "\n",
    "ax.plot(year_arr, combined_ratio_df[\"combined_ratio\"].tolist(), marker='o', markersize=8, label=\"combined_ratio\", linewidth=6)    \n",
    "\n",
    "\n",
    "# Setting graph properties\n",
    "plt.rcParams.update(params)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_xticks(np.arange(1558, 1875, step=30))\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Combined Plot\")\n",
    "ax.legend(prop={\"size\": 180})\n",
    "ax.grid()\n",
    "\n",
    "### Saving the plot\n",
    "fig.savefig(os.path.join(the_path, \"combined_land.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
